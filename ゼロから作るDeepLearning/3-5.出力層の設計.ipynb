{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力層の設計\n",
    "\n",
    "ニューラルネットワークは、「分類問題」、「回帰問題」の両方に用いることができる。  \n",
    "ただし、どちらに用いるかによって出力層の活性化関数を変更する必要がある。  \n",
    "一般的に、回帰問題では恒等関数を、分類問題ではソフトマックス関数を使う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恒等関数\n",
    "---\n",
    "入力をそのまま出力する。入ってきたものに何も手を加えずに出力する関数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソフトマックス関数\n",
    "---\n",
    "\n",
    "$ \\displaystyle y_k = \\frac{\\displaystyle exp({a_k})}{ \\displaystyle\\sum_{i=1}^n exp({a_i})}$\n",
    "\n",
    "- ソフトマックス関数の分子は入力信号 akの指数部分、分母はすべての入力信号の指数関数の和で構成される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "exp_a = np.exp(a) # 指数関数\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ソフトマックス関数の問題点\n",
    "- 指数関数は桁数が容易に大きくなるためオーバフローの懸念が発生する\n",
    "- 上記関数をそのまま使うとオーバフローに対応できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amoro/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/amoro/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 990])\n",
    "np.exp(a) / np.sum(np.exp(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この対策として入力信号の最大の値を引くことでオーバフローを防ぐことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 -10 -20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.max(a)\n",
    "print(a - c)\n",
    "\n",
    "np.exp(a - c) / np.sum(np.exp(a - c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c) # オーバフロー対策\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソフトマックス関数の特徴\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)\n",
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ソフトマックス関数の出力は0~1.0の実数になる\n",
    "- ソフトマックス関数の出力の総和は1になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この性質により、ソフトマックス関数の出力を「確率」として解釈することができる\n",
    "\n",
    "もうひとつの特徴としてソフトマックスは指数関数(y=exp(x))を使用する単調増加の関数であるため、各要素の大小関係は変わらない。\n",
    "\n",
    "ニューラルネットワークでクラス分類を行う場合、一般的に出力の大きいニューロンに相当するクラスだけを認識結果とする。\n",
    "ソフトマックス関数を用いても出力の一番大きいニューロンの場所は変わらない。そのためニューラルネットワークで分類を行う際は、出力層のソフトマックス関数を省略することができる。\n",
    "\n",
    "(指数関数の計算はそれなりにコンピュータの計算が必要になるので、出力層のソフトマックス関数は省略することが一般的)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "出力層のニューロンの数\n",
    "---\n",
    "- 出力層のニューロンの数は解くべき問題に応じて適宜決める必要がある。\n",
    "- クラス分類を行う問題では、出力層のニューロンの数は分類したいクラスの数に設定するのが一般的\n",
    "  - 例えば一つの数字画像を0~9までの数字に分類する問題であれば出力層のニューロンの数は10になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
